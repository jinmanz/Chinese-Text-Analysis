{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes some strategies for working with repeating phrases (also called n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['序幕', '诸事', '照计', '而行', '此书', '组织', '段', '一百', '段', '每段']\n"
     ]
    }
   ],
   "source": [
    "# import tokens generated from previous notebook:'Basic Chinese analytics'\n",
    "import csv\n",
    "with open('removeST_tokens.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    removeST_tokens = []\n",
    "    for row in reader:\n",
    "        removeST_tokens.extend(row)\n",
    "#check result\n",
    "print (removeST_tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will have a look at the top 50 phrase (consist of two tokens) using nltk.collocations(). \n",
    "Though convenient, this method is limited to bigrams (2 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "假象牙 烟嘴儿; 一串串 往下流; 庚子年 八国联军; 以眼还眼 以牙还牙; 前怕狼后怕虎 勇往直前; 人吃人 狗咬狗; 岳武穆 满江红;\n",
      "文天祥 史可法; 视而不见 听而不闻; 小三儿 小三儿; 几千年 几万年; 大学生 中学生; 太好了 太好了; 石榴树 夹竹桃; 老天爷\n",
      "不下雨; 征服者 被征服者; 小意思 小意思; 打扮起来 打扮起来; 冠晓荷 冠晓荷; 陈先生 还跟着; 不敢当 不敢当; 生娃娃 生娃娃;\n",
      "东方化 英国人; 中国化 英国人; 得不到 一官半职; 不要紧 不要紧; 老太婆 老太婆; 一会儿 睁开眼; 别着急 别着急; 不耐烦\n",
      "一个劲儿; 好孩子 好孩子; 大赤包 沉着脸; 老头子 老头子; 第二天 一清早; 千万别 任何人; 一会儿 放射出来; 逃出去 逃出去;\n",
      "筋疲力尽 一下子; 好容易 好容易; 大赤包 尤桐芳; 刘师傅 刘师傅; 活下去 活下去; 干什么 干什么; 对不起 对不起; 大赤包\n",
      "问晓荷; 胖菊子 打了个; 无可如何 笑了笑; 冠晓荷 祁瑞丰; 睡不着 一会儿; 干什么 想不出\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(removeST_tokens)\n",
    "text.collocations(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 祁 老人 天佑 太太\n",
      "8 丁 约翰 英国 府\n",
      "6 李 四爷 祁 老人\n",
      "6 丁 约翰 丁 约翰\n",
      "6 李 空山 李 空山\n",
      "5 摔死 一车 日本 兵\n",
      "5 钱 伯伯 钱 伯伯\n",
      "4 找 不到 话 说\n",
      "3 三个 月 粮食 咸菜\n",
      "3 北平 灾难 过不去 三个\n",
      "3 灾难 过不去 三个 月\n",
      "3 高 短 鼻子 纵起\n",
      "3 手心 上出 凉 汗\n",
      "3 楞 半天 低声 说\n",
      "3 天安门 日本 人开 机关枪\n"
     ]
    }
   ],
   "source": [
    "text_4grams = list(nltk.ngrams(text, 4)) \n",
    "text_4gramsFreqs = nltk.FreqDist(text_4grams) # determine frequency of four-grams\n",
    "for words, count in text_4gramsFreqs.most_common(15): # for the 15 most common four-grams\n",
    "    print(count, \" \".join(list(words))) # show the count and the create a string from the tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
